{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0dD9E4cIXrEO",
    "outputId": "b9009e3c-1d6b-48bd-8035-72a3710c383a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jBuFbXlpUX2l",
    "outputId": "09bec4d3-9cd5-4cd5-9e8a-0f38a920a19b",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'triu' from 'scipy.linalg' (/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scipy/linalg/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RegexpTokenizer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mporter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PorterStemmer\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m corpora, models\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcoherencemodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CoherenceModel\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/gensim/__init__.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.3.2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgensim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mhandlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/gensim/corpora/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexedcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndexedCorpus  \u001b[38;5;66;03m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmmcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MmCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleicorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BleiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/gensim/corpora/indexedcorpus.py:14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interfaces, utils\n\u001b[1;32m     16\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIndexedCorpus\u001b[39;00m(interfaces\u001b[38;5;241m.\u001b[39mCorpusABC):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/gensim/interfaces.py:19\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils, matutils\n\u001b[1;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCorpusABC\u001b[39;00m(utils\u001b[38;5;241m.\u001b[39mSaveLoad):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/gensim/matutils.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m entropy\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_blas_funcs, triu\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlapack\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_lapack_funcs\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m psi  \u001b[38;5;66;03m# gamma function utils\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'triu' from 'scipy.linalg' (/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scipy/linalg/__init__.py)"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import re\n",
    "import pyLDAvis.gensim_models\n",
    "import pickle \n",
    "import numpy as np, pandas as pd\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random_state = 0 \n",
    "\n",
    "doc_set = \"\"\"\n",
    "kawal yuk teman2 pemilu 2024\n",
    "update hasil quick count pilpres indonesia rabu 17 april 2024 via\n",
    "sobat polri ayo sukseskan pemilu jaga suara kita hindar dari kecurangan\n",
    "id wajib pilih cerdas hindari hoaks saat pemilu 2024\n",
    "kalo mimpi ketemu calon jangan coba dipilih deh kalo udah lanjur pilih jangan coba nyesel seriu\n",
    "akhbar pilih harga jatuh sindiket gelojoh baca lanjut pa\n",
    "update data pemilu 2024 17 april 2024 kpu\n",
    "sobat polri ayo sukseskan pemilu jaga suara kita hindar dari kecurangan\n",
    "travelling to jakarta from any region make sure your id is updated\n",
    "instruksi bupati sleman baru guru tinggi selenggara diskusi pemilu masa tenang\n",
    "pt angkasa pura i persero selenggara pengawasan suara hadap 856\n",
    "hari banyak 16 juta suara pemilih muda buat perubahan besar di indonesia\n",
    "pemkot jogja tengah susun ulang atur kait giat ajar ajar kbm tatap muka pemilu\n",
    "hingga ini 25 dagang malioboro ikut kampanye damai\n",
    "perempuan lebih mungkin alami efek samping pemilu banding laki\n",
    "lap kluster baharu kes hari masuk tujuh libat tempat kerja - kp kesihatan\n",
    "pemilu in karnataka id certificates mandatory for people coming to vote bsybjp\n",
    "gaiter loops auaaq balaclava bandanas - pemilu\n",
    "lanjut ica hari mertua alami stroke kondisi rahang miring ki\n",
    "rektor unp positif terlibat pemilu intensif kampus air tawar\n",
    "status kini task force operasi patuh pdrm baca lanjut paut\n",
    "ki ni mangwani yh py paisa lga k awam ko shifa dna ha aur\n",
    "public speaking butuh sampai informasi cara efisien akurat efektif dengar mampu menangk\n",
    "suntik 9 juta suara pemilih muda dampak lihat - beritasatu\n",
    "pengawasan pemilu rawat di wisma atlet mayor per 17 april 2024\n",
    "bansos pemilu kpk panggil sekjen kemensos dirjen linjamsos - - nasional\n",
    "tahun the media hotel and towers jadi posko tenaga pengawas pemilu\n",
    "patut syukur indonesia cepat sukses pemilu - - nasional\n",
    "catat angka mati hari tinggi akibat hoaks pemilu - - pikir rakyat\n",
    "budi bicara soal khawatir pemilu - cnbc indonesia\n",
    "tangan pemilu mungkin besar pengawasan ketat - bisnis\n",
    "pemilu akibat senjang sosial perempuan makin nyata -\n",
    "pemilu tahap tujuh - beritasatu\n",
    "klaim indonesia registrasi calon buat 4 hari sembuh dari kekalahan\n",
    "pemilu b117 duga masuk garut -\n",
    "mutasi ganda pemilu temu di india - okezone\n",
    "3 upaya ojk tangan dampak pemilu -\n",
    "aktor bollywood aamir khan positif terlibat pemilu -\n",
    "kampanye pemilu dagang pasar jemput paksa tenaga sehat polisi - inews\n",
    "wna terlibat pemilu sanur bal pakai id astrazeneca - jawa pos\n",
    "kampanye pemilu tni al tahap akhir jakarta -\n",
    "tim grup b piala menpora jalan pengawasan pemilu -\n",
    "malioboro ingat jalan kampanye damai -\n",
    "wakil bupati mamuju telat kampanye pemilu - -\n",
    "modus tipu lowong kerja bayar tengah pemilu - okezone\n",
    "mark sungkar positif terlibat pemilu - inews\n",
    "sedia layan pengawasan pemilu klinik pratama makmur jaya ciputat pamulang bintaro isi data pad\n",
    "kerala\n",
    "kenya\n",
    "segera daftar kuota 300 ribu pengawas pemilu\n",
    "sobat polri ayo sukseskan pemilu jaga suara kita hindar dari kecurangan\n",
    "program kampanye damai bangsa tan sri dato haji muhyiddin bin haji muhammad yassin perdana menteri malay\n",
    "innahhh da\n",
    "lansia jangan takut pilih warga bogor usia 104 tahun sehat pasca coblos\n",
    "mantap 16 juta suara pemilih muda tiba tanah air pemilu\n",
    "umbono lingayekethisi i pemilu isesekhona\n",
    "umum panjang pengawasan sesuai instruksi gubernur diy no 8 instr 2024\n",
    "panjang pengawasan mikro brebes laku 5 april 2024 pengawasan\n",
    "seni hibur boleh laksana buah hajat giat sosial masyarakat adala\n",
    "wakil presiden ma ruf amin imbau masyarakat jalan ibadah rumah lama pemilu langkah harus\n",
    "italia vs irlandia utara tak gentar sama badai hoaks italy\n",
    "laksana sambang pos sarlinmas pantai congot kulonprogo personel ditpolair polda diy ajak tugas untu\n",
    "kapolda diy irjen pol drs asep suhendar hadir tanding pertama piala menpora\n",
    "kamu malas hanya buang buang waktu kamu tak tahu bagaimana cara raih peluang bahkan pel\n",
    "survei idm pepet pdip golkar kian moncer jelang pemilu 2024 fraksigolkar\n",
    "ratus napi nusakambangan positif terlibat pemilu isolasi lapas via\n",
    "tahan lama pemilu bappenas dorong usaha laku digitalisasi bappenasri\n",
    "pemilu anak tunggu rekomendasi\n",
    "sambang kawasan toko jl am sangaji jetis kota yogyakarta personel patroli polsek jetis polresta yogyakar\n",
    "nu harap semua orang mau ikut pemilu nahdlatululama\n",
    "prokes 5m dagang unjung pasar bagi masker giat bagai upaya mendi\n",
    "sobat polri ayo sukseskan pemilu jaga suara kita hindar dari kecurangan\n",
    "sobat polri ayo sukseskan pemilu jaga suara kita hindar dari kecurangan\n",
    "sobat polri ayo sukseskan pemilu jaga suara kita hindar dari kecurangan\n",
    "naik 0 09 usd 1 182 gerak turun dorong tunda amp gelombang 3 m\n",
    "us index naik 0 03 level 92 55 ini di level tinggi akibat optimisme ak\n",
    "di-pertuan agong zahir rasa bangga warga pdrm atas korban bagai tugas baris hadap\n",
    "katno had dukung sukses program pemilu\n",
    "sobat polri ayo sukseskan pemilu jaga suara kita hindar dari kecurangan\n",
    "top news koran rakyat merdeka kampanye 1 juta sehari mimpi jokowi\n",
    "sobat polri ayo sukseskan pemilu jaga suara kita hindar dari kecurangan\n",
    "id astrazeneca selamat di malaysia\n",
    "top news koran rakyat merdeka ragu terap protokol sehat jaga pemprov tolak buka 26 tempat karaoke\n",
    "polri ayo sukseskan pemilu jaga suara a\n",
    "top news koran rakyat merdeka bule langgar prokes bal dah langsung pulangin negara asal aja bal\n",
    "top news koran rakyat merdeka soal sekolah tatap muka putus pekan depan satgascovid19\n",
    "update data hasil pemilu sulawesi barat tanggal 24 maret 2024 total sulbar positif 5358 sembuh 4980 tinggal 1\n",
    "taat prokes keren jauh kerumun kurang mobilitas polresjogja\n",
    "update kasus per tanggal 9 april 2024 website\n",
    "personel jaga pos polairud congot bripka catur widodo s h sama bripka agung h hadir panen raya kete\n",
    "kisne kaha tha 2024 me shadiyan km hongi ek bar lockdown hone do taara chadne wala hai pemilu\n",
    "330 perosonil polres ikut pemilu kunjung\n",
    "patuh protokol sehat 5m polresjogja\n",
    "tetep gumegrah ojo serah bebarengan lawan hoaks kanthi patuh protokol sehat 5m polresjogja\n",
    "pakai masker lindung virus pemilu polresjogja\n",
    "kini task force operasi patuh pdrm baca lanjut paut\n",
    "salam santun sebar hasil pemilu per tgl 09 apr\n",
    "19 yongereye ihungabana mu barokotse jenoside mu\n",
    "sapa masyarakat jumpa tidak lupa himbauan kamtibmas protokol sehat\n",
    "akibat makin kembang teknologi ini individualisme makin jamur hati tiap orang\n",
    "sobat jak moga semua segera gilir ikut pemilu ingat atau ses\n",
    "perintah terap bijak kendali pemilu pulih ekonomi cara imbang\n",
    "update data pemilu 9 april 2024 kpu\n",
    "in ai tempi del\n",
    "kait temu varian baru pemilu e484k satgas minta warga tak panik via\n",
    "plaza tawar layan check up screening pemilu -\n",
    "ji ah beri sumbang para siswa dampak pemilu - -\n",
    "kurang negara dunia rebut suara lawan pemilu - internasional kontan\n",
    "juang tes pemilu sulit cari murah kualitas -\n",
    "warga laku ziarah kubur tpu khusus jenazah pemilu -\n",
    "pegawai positif terlibat pemilu bank sumut cabang tebing tinggi tutup -\n",
    "pemilu mantan gubernur sumsel mahyudin tinggal dunia -\n",
    "hari pemilu aceh tingkat baru 42 orang -\n",
    "transparansi sedia informasi hasil pemilu - viva -\n",
    "luncur produk baru proteksi suara bantu tangan pemilu - kontan\n",
    "protokol pemilu maling mobil bikin polisi jadi bahan cemooh -\n",
    "sekolah tatap muka 10 000 lebih guru tangerang terlibat pemilu - inews\n",
    "sepeda aman lama pemilu - medcom id\n",
    "yogyakarta wajib bawa hasil pemilu - kompas tv\n",
    "luncur program mas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\".split(\"\\n\")[1:-1]\n",
    "\n",
    "\n",
    "stopword = ['pemilu', 'ayo', 'update', 'hasil', 'quick', 'count', 'indonesia', 'rabu', 'april', 'via', 'teman2', 'kita',\n",
    "    'wajib', 'pilih', 'cerdas', 'hindari', 'saat', 'pemilu', '2024', 'jangan', 'harga', 'data', 'kpu', 'sukseskan',\n",
    "    'suara', 'hindar', 'kecurangan', 'travelling', 'jakarta', 'region', 'make', 'sure', 'updated', 'instruksi',\n",
    "    'guru', 'tinggi', 'selenggara', 'masa', 'hingga', 'pemkot', 'tengah', 'susun', 'ulang', 'atur', 'kait', 'giat',\n",
    "    'ajar', 'kbm', 'ikut', 'kampanye', 'damai']\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "\n",
    "# list for tokenized documents in loop\n",
    "texts = []\n",
    "\n",
    "# loop through document list\n",
    "for i in doc_set:\n",
    "    \n",
    "    # clean and tokenize document string\n",
    "    raw = i.lower()\n",
    "    raw =  re.sub(r'\\b[0-9(.,)+]*\\b', '', raw)\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if not i in stopword and len(i) > 2]\n",
    "    \n",
    "    \n",
    "    # add tokens to list\n",
    "    texts.append(stopped_tokens)\n",
    "\n",
    "# turn our tokenized documents into a id <-> term dictionary\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "    \n",
    "# convert tokenized documents into a document-term matrix\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "#nilai K diganti\n",
    "for k in range(5, 6):\n",
    "\t# generate LDA model\n",
    "\tldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=k, id2word = dictionary, passes=20, iterations=100, alpha=[0.01]*k, eta=[0.01]*len(dictionary.keys()))\n",
    "\t#print(ldamodel.show_topics())\n",
    "\t# Compute Coherence Score\n",
    "\tcoherence_model_lda = CoherenceModel(model=ldamodel, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "\tcoherence_lda = coherence_model_lda.get_coherence()\n",
    "\tprint(k,ldamodel.log_perplexity(corpus),coherence_lda)  # a measure of how good the model is. lower the better.\n",
    "\n",
    "\n",
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=ldamodel, corpus=corpus, texts=texts)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "print(df_dominant_topic.head(10))\n",
    "\n",
    "\n",
    "\n",
    "# Sentence Coloring of N Sentences\n",
    "def topics_per_document(model, corpus, start=0, end=1):\n",
    "    corpus_sel = corpus[start:end]\n",
    "    dominant_topics = []\n",
    "    topic_percentages = []\n",
    "    for i, corp in enumerate(corpus_sel):\n",
    "        topic_percs = model[corp]\n",
    "        dominant_topic = sorted(topic_percs, key = lambda x: x[1], reverse=True)[0][0]\n",
    "        dominant_topics.append((i, dominant_topic))\n",
    "        topic_percentages.append(topic_percs)\n",
    "    return(dominant_topics, topic_percentages)\n",
    "\n",
    "dominant_topics, topic_percentages = topics_per_document(model=ldamodel, corpus=corpus, start=0, end=4)  \n",
    "\n",
    "# Distribution of Dominant Topics in Each Document\n",
    "df = pd.DataFrame(dominant_topics, columns=['Document_Id', 'Dominant_Topic'])\n",
    "\n",
    "dominant_topic_in_each_doc = df_dominant_topic.groupby('Dominant_Topic').size()\n",
    "print(dominant_topic_in_each_doc )\n",
    "df_dominant_topic_in_each_doc = dominant_topic_in_each_doc.to_frame(name='count').reset_index()\n",
    "\n",
    "# Total Topic Distribution by actual weight\n",
    "topic_weightage_by_doc = pd.DataFrame([dict(t) for t in topic_percentages])\n",
    "df_topic_weightage_by_doc = topic_weightage_by_doc.sum().to_frame(name='count').reset_index()\n",
    "\n",
    "# Top 3 Keywords for each Topic\n",
    "topic_top3words = [(i, topic) for i, topics in ldamodel.show_topics(formatted=False) \n",
    "                                 for j, (topic, wt) in enumerate(topics) if j < 3]\n",
    "\n",
    "df_top3words_stacked = pd.DataFrame(topic_top3words, columns=['topic_id', 'words'])\n",
    "df_top3words = df_top3words_stacked.groupby('topic_id').agg(', \\n'.join)\n",
    "df_top3words.reset_index(level=0,inplace=True)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10,4))\n",
    "\n",
    "# Topic Distribution by Dominant Topics\n",
    "ax1.bar(x='Dominant_Topic', height='count', data=df_dominant_topic_in_each_doc, width=.4, color='firebrick')\n",
    "ax1.set_xticks(range(df_dominant_topic_in_each_doc.Dominant_Topic.unique().__len__()))\n",
    "tick_formatter = FuncFormatter(lambda x, pos: 'Topik ' + str(x)+ '\\n' + df_top3words.loc[df_top3words.topic_id==x, 'words'].values[0])\n",
    "ax1.xaxis.set_major_formatter(tick_formatter)\n",
    "ax1.set_title('Jumlah Tweet Berdasarkan Topik', fontdict=dict(size=10))\n",
    "ax1.set_ylabel('Jumlah Tweet')\n",
    "ax1.set_ylim(0, 60)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ldaYT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
